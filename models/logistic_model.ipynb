{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix,roc_curve, auc, ConfusionMatrixDisplay\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "main_data = final_model_dataframe_facts # Acá debería ser el cargue del archivo de datos\n",
    "main_data[\"cog_level\"].value_counts() # Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable\n",
    "main_data[\"cog_level\"] = main_data[\"cog_level\"].replace({\"Bajo\": 0, \"Medio\": 1, \"Alto\": 2})\n",
    "main_data[\"cog_level\"].value_counts() # Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into train and test sets\n",
    "\n",
    "# --- Define X and y\n",
    "X = main_data[[\"age\", \"education_level\", \"languages_spoken\", \"gender\", \"average_time\", \"accuracy\"]]\n",
    "y = main_data[\"cog_level\"]\n",
    "\n",
    "print(X[[\"education_level\"]].value_counts())\n",
    "print(X[[\"languages_spoken\"]].value_counts())\n",
    "print(X[[\"gender\"]].value_counts())\n",
    "\n",
    "# --- Too few members for these categories\n",
    "X[\"gender\"] = X[\"gender\"].replace({\"Polygender\": \"Other\", \"Genderqueer\": \"Other\", \"Genderfluid\": \"Other\", \n",
    "                                   \"Non-binary\": \"Other\", \"Agender\": \"Other\", \"Bigender\": \"Other\"})\n",
    "\n",
    "print(X[\"gender\"].value_counts())\n",
    "\n",
    "# One hot encode categorical variables\n",
    "X = pd.get_dummies(X, columns=[\"education_level\", \"gender\", \"languages_spoken\"])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale age, time and accuracy\n",
    "\n",
    "# --- Small helper function\n",
    "def scale_vars(df, col_names):\n",
    "\n",
    "    for col_name in col_names:\n",
    "        # Get mean and St. Dev\n",
    "        x = df[col_name].mean()\n",
    "        sd = df[col_name].std()\n",
    "\n",
    "        # Scale\n",
    "        df[col_name] = (df[col_name] - x)/sd\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "# Scale\n",
    "X_train_sc = scale_vars(X_train, col_names=[\"age\", \"accuracy\", \"average_time\"])\n",
    "X_test_sc = scale_vars(X_test, col_names=[\"age\", \"accuracy\", \"average_time\"])\n",
    "\n",
    "# Define params grid and scoring metrics\n",
    "params = {\n",
    "    \"C\": [0.1, 0.5, 1]\n",
    "}\n",
    "scoring_metrics = [\"accuracy\", \"precision\", \"recall\"]\n",
    "\n",
    "# Set model and train\n",
    "logit_model = LogisticRegression(random_state=123, fit_intercept=False) # Falso porque tenemos dummies para todas las categorías\n",
    "model = GridSearchCV(estimator=logit_model, cv=4, param_grid=params, refit=\"accuracy\", scoring=scoring_metrics)\n",
    "model.fit(X_train_sc, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model and evaluate\n",
    "best_model = model.best_estimator_\n",
    "\n",
    "preds = best_model.predict(X_test_sc)\n",
    "# preds_proba = best_model.predict_proba(X_test) # To get probabilities for each class\n",
    "\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds, average=\"weighted\")\n",
    "f1 = f1_score(y_test, preds, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM\n",
    "print(confusion_matrix(y_test, preds, labels=model.classes_))\n",
    "\n",
    "# CM Heatmap\n",
    "cm = confusion_matrix(y_test, preds, labels=model.classes_)\n",
    "cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "cm_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "joblib.dump(best_model, \"modelo.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
